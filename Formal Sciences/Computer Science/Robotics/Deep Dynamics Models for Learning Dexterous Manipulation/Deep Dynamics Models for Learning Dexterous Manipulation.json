{
    "key": ["paper","doing","done","state","goal","method","conclusion"], 
    "paper":"Deep Dynamics Models for Learning Dexterous Manipulation",
    "doing":1,
    "done":0,
    "state":1,
    "goal":"",
    "method":
        [""],
    "conclusion":[""],
    "construct": {
        "title": "Deep Dynamics Models for Learning Dexterous Manipulation",    
        "author": "",
        "year": "",
        "journal": null,
        "url": null,
        "note": null,
        "abstract":  [
            
        ],
        "introduction": {
        
        },
        "2 Related Work": {
            "subsection": ""

        },
        "3 Deep Models for Dexterous Manipulation": {
            "propuse": "leverage the benefits of autonomous learning from data-driven methods while also enabling efficient and flexible task execution",
            "method": {
                "name": "PDDM",
                "build": [
                    "MPC with deep models",
                    "ensembles for model uncertainty estimation"
                ]
            },
            "3.1 Model-based Reinforcement Learning": {
                
            },
            "3.2 Learning the Dynamics": {
                
            },
            "3.3 Online Planning for Closed-Loop Control": {
                
            },
            "3.4 Overview": [
                "ensembles of deep dynamics models",
                "calculate H-step horizon candidate action sequences reward",
                "employ MPC",
                "perform optimal behavior and observe",
                ""
            ]
        },
        "4 Experimental Evaluation": {
            
            }
        }
    }
}